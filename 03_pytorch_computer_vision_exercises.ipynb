{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex99np2wFVt"
      },
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Sep 10 14:30:54 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1050      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   52C    P0             N/A / ERR!  |       0MiB /   4096MiB |      1%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.0+cu124\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFX7tc1w-en"
      },
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "source": [
        "1. Automotive\n",
        "2. Agriculture\n",
        "3. Sports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBK-WI6YxDYa"
      },
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "source": [
        "Overfitting is a common problem in machine learning. its when you have a model that performs well on the training data but poorly on the test data. Or vice versa. or maybe your model structure is not appropriate for the problem you're trying to solve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYFEqw8xK26"
      },
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "source": [
        "1. Cross-Validation: Partitioning the data into train and test sets. This helps ensure that the model is not overfitting.\n",
        "2. Regularization: Adding a penalty term to the loss function to prevent overfitting. L1 and L2 regularization are common methods.\n",
        "3. Early Stopping: Stopping training early if the model is not improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdEEFEqxM-8"
      },
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "source": [
        "meh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvf-3pODxXYI"
      },
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:41<00:00, 240068.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 58779.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:06<00:00, 247075.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZW-uAbxe_F"
      },
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QVFsYi1PbItE"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Shape: torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    image, label = train_data[i]\n",
        "    \n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "    plt.title(f'Label: {label}')\n",
        "    plt.axis(False)\n",
        "    \n",
        "plt.show()\n",
        "print(f'Image Shape: {image.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPDzW0wxhi3"
      },
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x16db0f01930>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x16db0f02e30>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              )\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCVfXk5xjYS"
      },
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self, input_features, hidden_units, output_features):\n",
        "        super().__init__()\n",
        "        self.cnn_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_features, out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3,stride=1, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.cnn_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.linear_block = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*7*7, out_features=output_features),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_block_1(x)\n",
        "        x = self.cnn_block_2(x)\n",
        "        # print(f'output of cnn_block_2 shape: {x.shape}')\n",
        "        x = self.linear_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MNISTModel(\n",
              "  (cnn_block_1): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (cnn_block_2): Sequential(\n",
              "    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (linear_block): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=392, out_features=10, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1 = MNISTModel(\n",
        "    input_features=1,\n",
        "    hidden_units=8,\n",
        "    output_features=len(class_names)\n",
        ").to(device)\n",
        "\n",
        "model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dummy data to find the flatten layer\n",
        "dummy_data = torch.randn(size=(1,28,28))\n",
        "dummy_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0290, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    print(model_1(dummy_data.unsqueeze(dim=0).to(device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_3zUr7xlhy"
      },
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "outputs": [],
      "source": [
        "# setup Loss Function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "from train_test_functions import train_step, test_step\n",
        "from helper_functions import accuracy_fn\n",
        "from helper_functions import print_train_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7745b4016a9048929bf670ef3aafdb0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0\n",
            "Train Loss: 2.20155 | Train Acc: 20.11%\n",
            "\n",
            "Test Loss: 1.42209 | Test Acc: 48.34%\n",
            "\n",
            "Epoch : 1\n",
            "Train Loss: 1.30927 | Train Acc: 48.66%\n",
            "\n",
            "Test Loss: 1.22063 | Test Acc: 50.11%\n",
            "\n",
            "Epoch : 2\n",
            "Train Loss: 0.89503 | Train Acc: 64.60%\n",
            "\n",
            "Test Loss: 0.74369 | Test Acc: 69.84%\n",
            "\n",
            "Epoch : 3\n",
            "Train Loss: 0.38278 | Train Acc: 85.65%\n",
            "\n",
            "Test Loss: 0.31543 | Test Acc: 87.67%\n",
            "\n",
            "Epoch : 4\n",
            "Train Loss: 0.32467 | Train Acc: 87.45%\n",
            "\n",
            "Test Loss: 0.29137 | Test Acc: 88.45%\n",
            "\n",
            "\n",
            "Train time on cuda: 87.615 seconds\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "train_model_1_start = timer()\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    print(f'Epoch : {epoch}')\n",
        "    train_step(model=model_1,\n",
        "               data_loader=train_dataloader,\n",
        "               loss_fn=loss_fn,\n",
        "               optimizer=optimizer,\n",
        "               accuracy_fn=accuracy_fn,\n",
        "               device=device)\n",
        "    test_step(model=model_1,\n",
        "              data_loader=test_dataloader,\n",
        "              loss_fn=loss_fn,\n",
        "              accuracy_fn=accuracy_fn,\n",
        "              device=device)\n",
        "    \n",
        "train_model_1_end = timer()\n",
        "\n",
        "total_train_model_1_time = print_train_time(train_model_1_start, train_model_1_end, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1CsHhPpxp1w"
      },
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQwzqlBWxrpG"
      },
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6bDhoWxt2y"
      },
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHS20cNTxwSi"
      },
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
