{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Pytorch Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Computer Vision Libraries in pytorch\n",
    "\n",
    "* `torchvision` - pytorch vision library\n",
    "* `torchvision.datasets` - for loading datasets\n",
    "* `torchvision.models` - for getting pretrained models\n",
    "* `torchvision.transforms` - for image transforms or manipulating images\n",
    "* `torch.utils.data.Dataset` - for base dataset class for pytorch\n",
    "* `torch.utils.data.DataLoader` - creating a python iterable over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# import matplotlib for visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting a dataset\n",
    "\n",
    "use fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data', # where to download data? \n",
    "    train=True, # do we want the training datasets\n",
    "    download=True, # do we want to download\n",
    "    transform=ToTensor(), # how do we want to transform the data\n",
    "    target_transform=None # how do we want to transform the labels\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of our image\n",
    "image.shape, label, train_data.classes[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "print(f'image shape : {image.shape}')\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(train_data.classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random images, plotting more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_index = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_index]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Loader\n",
    "\n",
    "our data right now is in the form of pytorch Datasets.\n",
    "\n",
    "DataLoader turns our dataset into a python iterable\n",
    "\n",
    "More specifically, we want to turn our data into batches (or mini-batches).\n",
    "\n",
    "Why would we do this?\n",
    "\n",
    "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32).\n",
    "2. It gives our neural network more chances to update its gradients per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# setup batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# turn datasets into python iterable\n",
    "train_dataloder = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "train_dataloder, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out yang udah di bikin\n",
    "print(f'Dataloader: {train_dataloder, test_dataloader}')\n",
    "print(f'Panjang Dataloader: {len(train_dataloder)} Batches of {BATCH_SIZE}')\n",
    "print(f'Panjang Dataloader: {len(test_dataloader)} Batches of {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek apa yang di dalem training dataloader\n",
    "train_freatures_batch, train_labels_batch = next(iter(train_dataloder))\n",
    "train_freatures_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a sample\n",
    "# torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_freatures_batch), size=[1]).item()\n",
    "img, label = train_freatures_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(train_data.classes[label])\n",
    "plt.axis(False)\n",
    "print(f'Image Size = {img.shape}')\n",
    "print(f'Label = {label}, Label Size = {label.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Model 0: Baseline Model\n",
    "\n",
    "When starting to build a series of machine learning modelling experiments, it's best practice to start with a baseline model.\n",
    "\n",
    "A baseline model is a simple model you will try and improve upon with subsequent models/experiments.\n",
    "\n",
    "In other words: start simply and add complexity when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# get single example\n",
    "x = train_freatures_batch[0]\n",
    "print(x.shape)\n",
    "\n",
    "# flatten the sample\n",
    "output = flatten_model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Model 0\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(train_data.classes),\n",
    ").to('cpu')\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    dummy_y = model_0(dummy_x)\n",
    "    print(dummy_y)\n",
    "    print(dummy_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Setup Loss Function, Optimizer and evaluation metrics\n",
    "\n",
    "* loss function - `nn.CrossentropyLoss()`\n",
    "* optimizer - `torch.optim.SGD()`\n",
    "* Evaluation metrics - classification problem, use accuracy evaluation metric `accuracy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions\n",
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time our experiments\n",
    "\n",
    "Machine learning is very experimental, what we want to track is:\n",
    "1. Model Performance (accuracy, loss, etc)\n",
    "2. How fast it runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float,\n",
    "                     end: float, \n",
    "                     device: torch.device = None):\n",
    "  \"\"\"Prints difference between start and end time.\"\"\"\n",
    "  total_time = end - start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training Loop and training a model on batches on data\n",
    "\n",
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps, calculate train loss per batch\n",
    "3. Loop through testing batches, perform testing steps, calculate test loss per batch\n",
    "4. Print out what's happening\n",
    "5. Time it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# device agnostic code\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# move model to gpu\n",
    "# model_0 = model_0.to(device)\n",
    "\n",
    "\n",
    "# set the seed and timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# set the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# create a training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_loss = 0\n",
    "    # add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloder):\n",
    "        model_0.train()\n",
    "        # move data to GPU\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f'Looked at {batch * len(X)}/{len(train_dataloder.dataset)} samples')\n",
    "            \n",
    "    # divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloder)\n",
    "    \n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0,0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            # X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X_test)\n",
    "            # 2. Calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            # 3. Calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "        # calculate the test loss  average per batch\n",
    "        test_loss /= len(test_data)\n",
    "        \n",
    "        # calculate the test accuracy average per batch\n",
    "        test_acc  /= len(test_dataloader)\n",
    "        \n",
    "    # print out whats happening\n",
    "    print(f'\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}%')\n",
    "    \n",
    "# calculate the training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predicstions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device agnostic Code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_mode(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device = device):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting data_loader\"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # make predictions\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # accumulate the loss and accuracy per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {'Model_Name': model.__class__.__name__,\n",
    "            'Model_loss': loss.item(),\n",
    "            'Model_Acc': acc}\n",
    "    \n",
    "# calculate model 0 results on test dataset\n",
    "model_0_results = eval_mode(model=model_0.to(device),\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device agnostic Code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 1: Build a better model using non linearity\n",
    "\n",
    "\n",
    "we learned about the power of non linearity in the previous section. we will use it in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model with linear and non linear\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape : int, \n",
    "                 hidden_units : int, \n",
    "                 out_shape : int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=out_shape),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model_1 = FashionMNISTModelV1(\n",
    "    input_shape=784,\n",
    "    hidden_units=10,\n",
    "    out_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "print(\"Device is :\", next(model_1.parameters()).device)\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Training loop\n",
    "\n",
    "Functionizing a training loop and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    '''\n",
    "    Performs a training with model trying to learn on data_loader\n",
    "    '''\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # put model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    # add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(data_loader):    \n",
    "        # put data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "        # 2. Calculate loss and acc (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "        train_acc += accuracy_fn(y_true=y, \n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "            \n",
    "    # divide total train loss and accuracy by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    '''Performs a testing loop step on model going over data_loader'''\n",
    "    test_loss, test_acc = 0, 0\n",
    "    # put the model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on inference mode context manager\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # send the data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and acc\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, \n",
    "                                    y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "        # adjust the metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        \n",
    "        # print out what's happening\n",
    "        print(f'\\nTest Loss: {test_loss:.5f} | Test Acc: {test_acc:.2f}%\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "# set epochs\n",
    "epochs = 3\n",
    "\n",
    "# create optimization and evaluation step\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epochs: {epoch}')\n",
    "    train_step(model=model_1,\n",
    "               data_loader=train_dataloder,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_1,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model_1 results in dictionary format\n",
    "model_1_results = eval_mode(model=model_1,\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model 2: Building a Convolutional Neural Network\n",
    "\n",
    "CNN is known as ConvNet\n",
    "\n",
    "CNN are the best to find patterns in visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a convolutional neural network\n",
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    '''Model Architecture that replicates the tinyVGG, a model from CNN explainer website'''\n",
    "    def __init__(self,\n",
    "                 input_shape : int,\n",
    "                 hidden_units : int,\n",
    "                 output_shape : int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 7 * 7,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(f'output of conv_block_1 shape: {x.shape}')\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(f'output of conv_block_2 shape: {x.shape}')\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can use print shape in the forward method to find out the shape of the image before going to classifier block to be flatten to test this you can use a random tensor that is in the same shape as your image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate model 2\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                              hidden_units=16,\n",
    "                              output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "print(model_2)\n",
    "print(next(model_2.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of random tensor test\n",
    "random_tensor_model_2 = torch.randn(size=(1,28,28))\n",
    "random_tensor_model_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "    print(model_2(random_tensor_model_2.unsqueeze(dim=0).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Stepping through `nn.Conv2D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# create a random image\n",
    "images = torch.randn(size=(32, 3, 64, 64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f'Image batch shape: {images.shape}')\n",
    "print(f'Single image shape: {test_image.shape}')\n",
    "print(f'Test Image :\\n {test_image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a sinlge conv2d layer\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "# Pass the data through the convolutional layer \n",
    "conv_output = conv_layer(test_image)\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Stepping Through MaxPooling2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out original image shape without unsqueezed dimension\n",
    "print(f'Test Image original shape {test_image.shape}')\n",
    "\n",
    "\n",
    "# create a sample maxpooling2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# pass data through the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image)\n",
    "print(f'shape after going through conv_layer(): {test_image_through_conv.shape}')\n",
    "\n",
    "# pass data through the maxpool_layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f'shape after going conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Setup a loss function and optimizer for model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Training and testing model_2 using our training and test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# measure time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_time_start_on_model_2 = timer()\n",
    "\n",
    "# number of epochs\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    train_step(model=model_2,\n",
    "               data_loader=train_dataloder,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_2,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "train_time_end_on_model_2 = timer()\n",
    "\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_on_model_2,\n",
    "                                            end=train_time_end_on_model_2,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model_2 results\n",
    "model_2_results = eval_mode(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare model results and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add training time to results comparison\n",
    "compare_results['training time'] = [total_train_time_model_0,\n",
    "                                    total_train_time_model_1,\n",
    "                                    total_train_time_model_2]\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize our model results\n",
    "compare_results.set_index('Model_Name')['Model_Acc'].plot(kind='barh')\n",
    "plt.xlabel('Accuracy (%)')\n",
    "plt.ylabel('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Make and evaluate random predictions with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    model: torch.nn.Module,\n",
    "    data: list,\n",
    "    device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # prepare the sample (add a batch dimension and pass to target device)\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "            # forward pass (model outputs raw logits)\n",
    "            pred_logit = model(sample)\n",
    "            # get prediction probability\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "            # get pred prob off the gpu for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "            \n",
    "    # stack the pred probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "# view the first sample shape\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_samples[0].squeeze(), cmap='gray')\n",
    "plt.title(test_data.classes[test_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs = make_predictions(model=model_2,\n",
    "                              data=test_samples)\n",
    "\n",
    "# view the first two prediction probabilities\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction probabilities to labels\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "print(pred_classes)\n",
    "print(\"\\n\",test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions\n",
    "plt.figure(figsize=(9,9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # create a subplot\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    \n",
    "    # plot the target image\n",
    "    plt.imshow(sample.squeeze(), cmap='gray')\n",
    "    \n",
    "    # find the prediction label in text forms\n",
    "    pred_label= test_data.classes[pred_classes[i]]\n",
    "    \n",
    "    # get the truth label\n",
    "    truth_label = test_data.classes[test_labels[i]]\n",
    "    \n",
    "    # create a title for the plot\n",
    "    title_text = f'Pred: {pred_label} | Truth: {truth_label}'\n",
    "    \n",
    "    # check for equality between pred and truth and change color of title text\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=10, c='g')\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=10, c='r')\n",
    "        \n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Making a confusion matrix for further prediction evaluation\n",
    "\n",
    "1. make predictions with our trained model on test dataset\n",
    "2. make a confusion matrix with torchmetrics\n",
    "3. plot the confusion matrix using mlxtend.plotting.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "mlxtend.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with trained models\n",
    "y_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "  for X, y in tqdm(test_dataloader, desc=\"Making predictions...\"):\n",
    "    # Send the data and targets to target device\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    # Do the forward pass\n",
    "    y_logit = model_2(X)\n",
    "    # Turn predictions from logits -> prediction probabilities -> prediction labels\n",
    "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
    "    # Put prediction on CPU for evaluation\n",
    "    y_preds.append(y_pred.cpu())\n",
    "\n",
    "# Concatenate list of predictions into a tensor\n",
    "# print(y_preds)\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "y_pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup confusion matrix instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# 3. plot confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. saving and load best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# create model directory path\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create model save\n",
    "MODEL_NAME = '03_Pytorch_vision_model_2.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# save the model\n",
    "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
    "torch.save(obj= model_2.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new instance of model and load it\n",
    "# create a new seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                                     hidden_units=16,\n",
    "                                     output_shape=len(class_names))\n",
    "\n",
    "# load the state dict\n",
    "loaded_model_2.load_state_dict(torch.load(f='models/03_Pytorch_vision_model_2.pth'))\n",
    "\n",
    "# send the loaded model to device\n",
    "loaded_model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the loaded model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "loaded_model_2_results = eval_mode(\n",
    "    model=loaded_model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "loaded_model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if model results are close to each other\n",
    "torch.isclose(torch.tensor(model_2_results['Model_loss']),\n",
    "              torch.tensor(loaded_model_2_results['Model_loss']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
